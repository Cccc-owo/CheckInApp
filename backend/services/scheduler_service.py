import logging
import os
import time
from datetime import datetime
from pathlib import Path
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from filelock import FileLock
from sqlalchemy.orm import Session
from croniter import croniter

from backend.config import settings
from backend.models import get_db, User, CheckInTask
from backend.services.check_in_service import CheckInService
from backend.services.admin_service import AdminService

logger = logging.getLogger(__name__)

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler = None
scheduler_lock = None


def load_scheduled_tasks(db: Session, scheduler_instance):
    """
    ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰å¯ç”¨çš„å®šæ—¶ä»»åŠ¡å¹¶æ·»åŠ åˆ° APScheduler

    åªåŠ è½½æ»¡è¶³ä»¥ä¸‹æ¡ä»¶çš„ä»»åŠ¡ï¼š
    - is_active = True
    - cron_expression IS NOT NULL

    Args:
        db: æ•°æ®åº“ä¼šè¯
        scheduler_instance: APScheduler BackgroundScheduler å®ä¾‹

    Returns:
        åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    logger.info("æ­£åœ¨ä»æ•°æ®åº“åŠ è½½å®šæ—¶ä»»åŠ¡...")

    # ç§»é™¤æ‰€æœ‰ç°æœ‰çš„åŠ¨æ€ä»»åŠ¡ï¼ˆä¿ç•™ç³»ç»Ÿä»»åŠ¡ï¼‰
    for job in scheduler_instance.get_jobs():
        if job.id.startswith('task_'):
            scheduler_instance.remove_job(job.id)

    # æŸ¥è¯¢æ‰€æœ‰å¯ç”¨ä¸”æœ‰ cron è¡¨è¾¾å¼çš„ä»»åŠ¡
    tasks = db.query(CheckInTask).filter(
        CheckInTask.is_active == True,
        CheckInTask.cron_expression.isnot(None)
    ).all()

    loaded_count = 0
    skipped_count = 0
    error_count = 0

    for task in tasks:
        try:
            # éªŒè¯ cron è¡¨è¾¾å¼
            cron_str = str(task.cron_expression) if task.cron_expression else None
            if not cron_str or not croniter.is_valid(cron_str):
                logger.warning(f"è·³è¿‡ä»»åŠ¡ {task.id}: æ— æ•ˆçš„ cron è¡¨è¾¾å¼ '{task.cron_expression}'")
                skipped_count += 1
                continue

            # åˆ›å»ºä»»åŠ¡ ID
            job_id = f"task_{task.id}"

            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å­˜åœ¨
            if scheduler_instance.get_job(job_id):
                logger.debug(f"ä»»åŠ¡ {task.id} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                continue

            # æ·»åŠ ä»»åŠ¡åˆ°è°ƒåº¦å™¨
            scheduler_instance.add_job(
                func=scheduled_check_in_task,
                trigger=CronTrigger.from_crontab(cron_str),
                id=job_id,
                name=f"CheckIn-Task-{task.id}",
                args=[task.id],
                replace_existing=True
            )

            logger.info(f"âœ… åŠ è½½ä»»åŠ¡ {task.id}: {task.name} (Cron: {task.cron_expression})")
            loaded_count += 1

        except Exception as e:
            logger.error(f"âŒ åŠ è½½ä»»åŠ¡ {task.id} æ—¶å‡ºé”™: {str(e)}")
            error_count += 1

    result = {
        "loaded": loaded_count,
        "skipped": skipped_count,
        "errors": error_count,
        "total": len(tasks)
    }

    logger.info(f"ä»»åŠ¡åŠ è½½å®Œæˆ: {result}")
    return result


def scheduled_check_in_task(task_id: int):
    """
    æ‰§è¡ŒæŒ‡å®šä»»åŠ¡çš„å®šæ—¶æ‰“å¡

    è¿™æ˜¯ç”± APScheduler åœ¨ cron è§¦å‘å™¨è§¦å‘æ—¶è°ƒç”¨çš„å‡½æ•°
    ä½¿ç”¨ä¸æ‰¹é‡æ‰“å¡ç›¸åŒçš„é€»è¾‘
    """
    from backend.models.database import SessionLocal

    db = SessionLocal()
    try:
        task = db.query(CheckInTask).filter(CheckInTask.id == task_id).first()
        if not task:
            logger.error(f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
            return

        if not task.is_scheduled_enabled:
            logger.info(f"ä»»åŠ¡ {task_id} æœªå¯ç”¨å®šæ—¶æ‰“å¡ (is_active={task.is_active}, cron={task.cron_expression})")
            return

        logger.info(f"ğŸ¤– æ‰§è¡Œå®šæ—¶æ‰“å¡ä»»åŠ¡ {task_id}")

        # å¼€å§‹å¼‚æ­¥æ‰“å¡
        CheckInService.start_async_check_in(task, "scheduled", db)

    except Exception as e:
        logger.error(f"æ‰§è¡Œå®šæ—¶æ‰“å¡ä»»åŠ¡ {task_id} æ—¶å‡ºé”™: {str(e)}", exc_info=True)
    finally:
        db.close()


def cleanup_expired_pending_users():
    """å®šæ—¶æ¸…ç†è¿‡æœŸæœªå®¡æ‰¹ç”¨æˆ·ï¼ˆ24å°æ—¶æœªå®¡æ‰¹ï¼‰"""
    logger.info("Scheduler: æ­£åœ¨æ¸…ç†è¿‡æœŸæœªå®¡æ‰¹ç”¨æˆ·...")

    try:
        # åˆ›å»ºæ•°æ®åº“ä¼šè¯
        db = next(get_db())

        try:
            count = AdminService.delete_expired_pending_users(db)
            logger.info(f"Scheduler: å·²åˆ é™¤ {count} ä¸ªè¿‡æœŸæœªå®¡æ‰¹ç”¨æˆ·")
        finally:
            db.close()

    except Exception as e:
        logger.error(f"Scheduler: æ¸…ç†è¿‡æœŸç”¨æˆ·ä»»åŠ¡å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)


def check_token_expiration():
    """
    æ£€æŸ¥ Token æ˜¯å¦å³å°†è¿‡æœŸï¼Œå¹¶å‘é€é‚®ä»¶æé†’

    æ£€æŸ¥æ‰€æœ‰ç”¨æˆ·çš„ Tokenï¼Œå¦‚æœåœ¨ 30 åˆ†é’Ÿå†…è¿‡æœŸï¼Œå‘é€æé†’é‚®ä»¶
    æ³¨æ„ï¼šç°åœ¨éœ€è¦æ£€æŸ¥ç”¨æˆ·çš„ä»»åŠ¡ï¼Œå› ä¸ºé‚®ç®±åœ°å€åœ¨ä»»åŠ¡ä¸­
    """
    logger.info("Scheduler: æ­£åœ¨æ‰§è¡Œ Token è¿‡æœŸæ£€æŸ¥...")

    try:
        # åˆ›å»ºæ•°æ®åº“ä¼šè¯
        db = next(get_db())

        try:
            # è·å–æ‰€æœ‰ç”¨æˆ·
            users = db.query(User).all()
            current_timestamp = int(datetime.now().timestamp())

            notified_count = 0

            for user in users:
                if not user.jwt_exp or user.jwt_exp == "0":
                    continue

                try:
                    exp_timestamp = int(user.jwt_exp)

                    # æ£€æŸ¥æ˜¯å¦åœ¨ 30 åˆ†é’Ÿå†…è¿‡æœŸï¼ˆ0 < å‰©ä½™æ—¶é—´ < 1800ç§’ï¼‰
                    time_until_expiry = exp_timestamp - current_timestamp

                    if 0 < time_until_expiry < 1800:  # 30åˆ†é’Ÿ = 1800ç§’
                        # ä½¿ç”¨ç”¨æˆ·è´¦æˆ·çš„é‚®ç®±å‘é€é€šçŸ¥
                        if user.email:
                            logger.info(f"ç”¨æˆ· {user.alias} çš„ Token å³å°†è¿‡æœŸï¼Œå‘é€é‚®ä»¶æé†’åˆ° {user.email}...")
                            from backend.services.email_service import EmailService
                            jwt_exp_value = user.jwt_exp
                            jwt_exp_str = str(jwt_exp_value) if jwt_exp_value is not None else "0"
                            EmailService.notify_token_expiring(user, jwt_exp_str)
                            notified_count += 1

                except ValueError:
                    logger.warning(f"ç”¨æˆ· {user.alias} çš„ jwt_exp æ ¼å¼ä¸æ­£ç¡®: {user.jwt_exp}")
                    continue

            logger.info(f"Scheduler: Token è¿‡æœŸæ£€æŸ¥å®Œæˆï¼Œå…±å‘é€ {notified_count} å°æé†’é‚®ä»¶")

        finally:
            db.close()

    except Exception as e:
        logger.error(f"Scheduler: Token è¿‡æœŸæ£€æŸ¥ä»»åŠ¡å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)


def scheduled_check_in():
    """
    å®šæ—¶æ‰“å¡ä»»åŠ¡ï¼šæ¯å¤©å®šæ—¶ä¸ºæ‰€æœ‰å¯ç”¨çš„ä»»åŠ¡æ‰§è¡Œæ‰“å¡
    """
    logger.info("Scheduler: å¼€å§‹æ‰§è¡Œå®šæ—¶æ‰“å¡ä»»åŠ¡...")

    try:
        # åˆ›å»ºæ•°æ®åº“ä¼šè¯
        db = next(get_db())

        try:
            result = CheckInService.scheduled_check_in_all_active_tasks(db)

            logger.info(
                f"Scheduler: å®šæ—¶æ‰“å¡ä»»åŠ¡å®Œæˆï¼Œ"
                f"æ€»è®¡: {result['total']}, "
                f"æˆåŠŸ: {result['success']}, "
                f"å¤±è´¥: {result['failure']}, "
                f"è·³è¿‡: {result['skipped']}"
            )

        finally:
            db.close()

    except Exception as e:
        logger.error(f"Scheduler: å®šæ—¶æ‰“å¡ä»»åŠ¡å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)


def cleanup_old_sessions():
    """
    æ¸…ç†æ—§çš„ä¼šè¯æ–‡ä»¶

    åˆ é™¤è¶…è¿‡æŒ‡å®šæ—¶é—´çš„ä¼šè¯æ–‡ä»¶
    """
    logger.info("Scheduler: å¼€å§‹æ¸…ç†æ—§ä¼šè¯æ–‡ä»¶...")

    try:
        session_dir = settings.SESSION_DIR

        if not session_dir.exists():
            logger.info("Scheduler: ä¼šè¯ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç†")
            return

        current_time = time.time()
        cleanup_threshold = settings.SESSION_CLEANUP_HOURS * 3600  # è½¬æ¢ä¸ºç§’

        deleted_count = 0

        for file_path in session_dir.glob("*.json"):
            try:
                # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                file_mtime = file_path.stat().st_mtime
                file_age = current_time - file_mtime

                # å¦‚æœæ–‡ä»¶è¶…è¿‡é˜ˆå€¼ï¼Œåˆ é™¤å®ƒ
                if file_age > cleanup_threshold:
                    # åŒæ—¶åˆ é™¤å¯¹åº”çš„é”æ–‡ä»¶
                    lock_file = session_dir / f"{file_path.stem}.json.lock"

                    file_path.unlink()
                    if lock_file.exists():
                        lock_file.unlink()

                    deleted_count += 1
                    logger.debug(f"åˆ é™¤æ—§ä¼šè¯æ–‡ä»¶: {file_path.name}")

            except Exception as e:
                logger.error(f"åˆ é™¤ä¼šè¯æ–‡ä»¶ {file_path.name} æ—¶å‡ºé”™: {e}")

        logger.info(f"Scheduler: ä¼šè¯æ–‡ä»¶æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶")

    except Exception as e:
        logger.error(f"Scheduler: æ¸…ç†ä¼šè¯æ–‡ä»¶ä»»åŠ¡å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)


def start_scheduler():
    """
    å¯åŠ¨è°ƒåº¦å™¨

    ä½¿ç”¨æ–‡ä»¶é”ç¡®ä¿åœ¨å¤šè¿›ç¨‹éƒ¨ç½²æ—¶åªæœ‰ä¸€ä¸ªè°ƒåº¦å™¨è¿è¡Œ
    """
    global scheduler, scheduler_lock

    # åˆ›å»ºè°ƒåº¦å™¨é”æ–‡ä»¶
    lock_file = settings.BASE_DIR / "scheduler.lock"
    scheduler_lock = FileLock(lock_file, timeout=1)

    try:
        # å°è¯•è·å–é”
        scheduler_lock.acquire(blocking=False)

        logger.info("æˆåŠŸè·å–è°ƒåº¦å™¨é”ï¼Œå¯åŠ¨è°ƒåº¦å™¨...")

        # åˆ›å»ºåå°è°ƒåº¦å™¨
        scheduler = BackgroundScheduler(timezone="Asia/Shanghai")

        # æ·»åŠ  Token è¿‡æœŸæ£€æŸ¥ä»»åŠ¡ï¼ˆæ¯éš”æŒ‡å®šåˆ†é’Ÿï¼‰
        scheduler.add_job(
            check_token_expiration,
            trigger="interval",
            minutes=settings.TOKEN_CHECK_INTERVAL_MINUTES,
            id="check_token_expiration",
            name="Token è¿‡æœŸæ£€æŸ¥ä»»åŠ¡",
            replace_existing=True
        )
        logger.info(
            f"å·²æ·»åŠ  Token è¿‡æœŸæ£€æŸ¥ä»»åŠ¡: æ¯ {settings.TOKEN_CHECK_INTERVAL_MINUTES} åˆ†é’Ÿ"
        )

        # æ·»åŠ ä¼šè¯æ–‡ä»¶æ¸…ç†ä»»åŠ¡ï¼ˆæ¯éš”æŒ‡å®šå°æ—¶ï¼‰
        scheduler.add_job(
            cleanup_old_sessions,
            trigger="interval",
            hours=settings.SESSION_CLEANUP_INTERVAL_HOURS,
            id="cleanup_old_sessions",
            name="æ¸…ç†æ—§ä¼šè¯æ–‡ä»¶ä»»åŠ¡",
            replace_existing=True
        )
        logger.info(
            f"å·²æ·»åŠ ä¼šè¯æ¸…ç†ä»»åŠ¡: æ¯ {settings.SESSION_CLEANUP_INTERVAL_HOURS} å°æ—¶"
        )

        # æ·»åŠ æ¸…ç†è¿‡æœŸæœªå®¡æ‰¹ç”¨æˆ·ä»»åŠ¡ï¼ˆæ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡ï¼‰
        scheduler.add_job(
            cleanup_expired_pending_users,
            trigger="interval",
            hours=1,
            id="cleanup_expired_pending_users",
            name="æ¸…ç†è¿‡æœŸæœªå®¡æ‰¹ç”¨æˆ·ä»»åŠ¡",
            replace_existing=True
        )
        logger.info("å·²æ·»åŠ æ¸…ç†è¿‡æœŸæœªå®¡æ‰¹ç”¨æˆ·ä»»åŠ¡: æ¯ 1 å°æ—¶")

        # æ–°å¢ï¼šä»æ•°æ®åº“åŠ è½½åŠ¨æ€ä»»åŠ¡
        db = next(get_db())
        try:
            load_scheduled_tasks(db, scheduler)
        finally:
            db.close()

        # å¯åŠ¨è°ƒåº¦å™¨
        scheduler.start()
        logger.info("è°ƒåº¦å™¨å·²å¯åŠ¨")

    except Exception as e:
        logger.warning(f"æ— æ³•è·å–è°ƒåº¦å™¨é”æˆ–å¯åŠ¨å¤±è´¥: {e}")
        logger.info("å¯èƒ½å…¶ä»–è¿›ç¨‹å·²ç»åœ¨è¿è¡Œè°ƒåº¦å™¨ï¼Œè·³è¿‡å¯åŠ¨")
        scheduler_lock = None


def stop_scheduler():
    """
    åœæ­¢è°ƒåº¦å™¨å¹¶é‡Šæ”¾é”
    """
    global scheduler, scheduler_lock

    if scheduler:
        logger.info("æ­£åœ¨åœæ­¢è°ƒåº¦å™¨...")
        scheduler.shutdown()
        logger.info("è°ƒåº¦å™¨å·²åœæ­¢")

    if scheduler_lock:
        try:
            scheduler_lock.release()
            logger.info("å·²é‡Šæ”¾è°ƒåº¦å™¨é”")
        except Exception as e:
            logger.warning(f"é‡Šæ”¾è°ƒåº¦å™¨é”æ—¶å‡ºé”™: {e}")
